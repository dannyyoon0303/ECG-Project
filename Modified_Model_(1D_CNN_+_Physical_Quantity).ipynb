{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dannyyoon0303/ECG-Project/blob/main/Modified_Model_(1D_CNN_%2B_Physical_Quantity).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkH6J45_6ko9",
        "outputId": "5c2fb147-4807-45ba-a016-738307f19652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install neurokit2\n",
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gph5t67_w1g",
        "outputId": "12d1900e-5320-49cb-f48a-f232d1da19f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neurokit2\n",
            "  Downloading neurokit2-0.2.1-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from neurokit2) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from neurokit2) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neurokit2) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from neurokit2) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neurokit2) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->neurokit2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurokit2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurokit2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurokit2) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurokit2) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->neurokit2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->neurokit2) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->neurokit2) (2022.2.1)\n",
            "Installing collected packages: neurokit2\n",
            "Successfully installed neurokit2-0.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.48.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 8s (55.1 MB/s)\n",
            "(Reading database ... 159447 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 159425 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RWMyNXpAUrC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import neurokit2 as nk\n",
        "import tensorflow as tf \n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
        "    concatenate, Add\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QJNlPeUAVbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372086ea-9007-40ad-954b-9592ba152c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0         1         2         3         4         5         6    \\\n",
            "1      1.000000  0.693965  0.336207  0.271552  0.250000  0.211207  0.250000   \n",
            "2      0.139535  0.682171  0.782946  0.000000  0.170543  0.472868  0.604651   \n",
            "3      0.944751  0.906077  0.646409  0.414365  0.209945  0.093923  0.060773   \n",
            "4      0.956221  0.898618  0.826037  0.740783  0.625576  0.531106  0.414747   \n",
            "5      0.956416  0.869249  0.290557  0.000000  0.152542  0.251816  0.285714   \n",
            "...         ...       ...       ...       ...       ...       ...       ...   \n",
            "87550  0.968750  1.000000  0.718750  0.368056  0.059028  0.059028  0.142361   \n",
            "87551  1.000000  0.676157  0.064057  0.021352  0.110320  0.092527  0.064057   \n",
            "87552  0.952381  0.935374  0.632653  0.241497  0.010204  0.000000  0.112245   \n",
            "87553  0.835206  0.838951  0.632959  0.284644  0.011236  0.041199  0.153558   \n",
            "87554  1.000000  0.887978  0.494536  0.245902  0.147541  0.125683  0.084699   \n",
            "\n",
            "            7         8         9    ...  183  184  185  186  187       188  \\\n",
            "1      0.254310  0.224138  0.262931  ...  0.0  0.0  0.0  0.0  0.0  1.530465   \n",
            "2      0.604651  0.635659  0.620155  ...  0.0  0.0  0.0  0.0  0.0  1.603813   \n",
            "3      0.088398  0.099448  0.077348  ...  0.0  0.0  0.0  0.0  0.0  1.548877   \n",
            "4      0.332949  0.236175  0.193548  ...  0.0  0.0  0.0  0.0  4.0  1.389392   \n",
            "5      0.288136  0.302663  0.295400  ...  0.0  0.0  0.0  0.0  0.0  1.573206   \n",
            "...         ...       ...       ...  ...  ...  ...  ...  ...  ...       ...   \n",
            "87550  0.229167  0.284722  0.322917  ...  0.0  0.0  0.0  0.0  0.0  1.520045   \n",
            "87551  0.071174  0.064057  0.053381  ...  0.0  0.0  0.0  0.0  0.0  1.767804   \n",
            "87552  0.173469  0.251701  0.241497  ...  0.0  0.0  0.0  0.0  0.0  1.493471   \n",
            "87553  0.220974  0.265918  0.258427  ...  0.0  0.0  0.0  0.0  0.0  1.571261   \n",
            "87554  0.054645  0.032787  0.030055  ...  0.0  0.0  0.0  0.0  0.0  1.687787   \n",
            "\n",
            "            189       190       191       192  \n",
            "1      1.453280  1.022628  4.767442  2.883668  \n",
            "2      1.902441  1.044516  5.199439  3.319249  \n",
            "3      1.467211  1.027952  5.192564  3.085757  \n",
            "4      1.433615  1.016436  4.900914  3.983967  \n",
            "5      1.409957  1.017995  3.767292  2.860872  \n",
            "...         ...       ...       ...       ...  \n",
            "87550  1.438726  1.032076  5.574859  2.912823  \n",
            "87551  1.348661  1.016436  3.287995  2.696607  \n",
            "87552  1.483619  1.035413  5.494558  2.790833  \n",
            "87553  1.597024  1.034304  5.363139  2.829733  \n",
            "87554  1.313509  1.022628  4.034697  2.881848  \n",
            "\n",
            "[87554 rows x 193 columns]\n"
          ]
        }
      ],
      "source": [
        "train_file_path = \"/content/drive/MyDrive/[Project] 윤정현 - ECG/Data/full_training_set(size=87554).csv\"\n",
        "test_file_path = \"/content/drive/MyDrive/[Project] 윤정현 - ECG/Data/full_test_set(size=21892).csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_file_path, header=None)[1:].astype(float)\n",
        "print(df_train)\n",
        "df_train = df_train.sample(frac=1)\n",
        "df_test = pd.read_csv(test_file_path, header=None)[1:].astype(float)\n",
        "\n",
        "Y = np.array(df_train[187].values).astype(np.int8)\n",
        "X_ecg = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
        "X_physical = np.array(df_train[list(range(188, 193))].values)[..., np.newaxis]\n",
        "\n",
        "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
        "X_ecg_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]\n",
        "X_physical_test = np.array(df_test[list(range(188, 193))].values)[..., np.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du5NuwNbAad0"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    nclass = 5\n",
        "    inp_ecg = Input(shape=(187, 1))\n",
        "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp_ecg)\n",
        "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = GlobalMaxPool1D()(img_1)\n",
        "    img_1 = Dropout(rate=0.2)(img_1)\n",
        "    \n",
        "   \n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    inp_physical = Input(shape=(5))\n",
        "    concat_1 = concatenate([dense_1, inp_physical])\n",
        "    dense_2 = Dense(64, activation=activations.relu, name=\"dense_2\")(concat_1)\n",
        "    dense_3 = Dense(nclass, activation=activations.softmax, name=\"dense_3_mitbih\")(dense_2)\n",
        "\n",
        "    model = models.Model(inputs=[inp_ecg, inp_physical], outputs=dense_3)\n",
        "    opt = tf.optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QToWHjC9AdqO",
        "outputId": "3b294bea-2baf-413e-eda8-cc40cee002f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 187, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 183, 16)      96          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 179, 16)      1296        ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 89, 16)       0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 89, 16)       0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 87, 32)       1568        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 85, 32)       3104        ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 42, 32)      0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 42, 32)       0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 40, 32)       3104        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 38, 32)       3104        ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 19, 32)      0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 19, 32)       0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 17, 256)      24832       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 15, 256)      196864      ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 256)         0           ['conv1d_7[0][0]']               \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 256)          0           ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           16448       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 69)           0           ['dense_1[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           4480        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3_mitbih (Dense)         (None, 5)            325         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 255,221\n",
            "Trainable params: 255,221\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "\n",
            "Epoch 1: val_acc improved from -inf to 0.93981, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 23s - loss: 0.3452 - acc: 0.9019 - val_loss: 0.2315 - val_acc: 0.9398 - lr: 0.0010 - 23s/epoch - 9ms/step\n",
            "Epoch 2/1000\n",
            "\n",
            "Epoch 2: val_acc improved from 0.93981 to 0.95751, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 15s - loss: 0.2083 - acc: 0.9409 - val_loss: 0.1483 - val_acc: 0.9575 - lr: 0.0010 - 15s/epoch - 6ms/step\n",
            "Epoch 3/1000\n",
            "\n",
            "Epoch 3: val_acc improved from 0.95751 to 0.96677, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.1599 - acc: 0.9546 - val_loss: 0.1248 - val_acc: 0.9668 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 4/1000\n",
            "\n",
            "Epoch 4: val_acc did not improve from 0.96677\n",
            "2463/2463 - 14s - loss: 0.1398 - acc: 0.9612 - val_loss: 0.1463 - val_acc: 0.9591 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 5/1000\n",
            "\n",
            "Epoch 5: val_acc improved from 0.96677 to 0.97465, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 15s - loss: 0.1249 - acc: 0.9653 - val_loss: 0.0927 - val_acc: 0.9746 - lr: 0.0010 - 15s/epoch - 6ms/step\n",
            "Epoch 6/1000\n",
            "\n",
            "Epoch 6: val_acc improved from 0.97465 to 0.97579, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.1145 - acc: 0.9680 - val_loss: 0.0864 - val_acc: 0.9758 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 7/1000\n",
            "\n",
            "Epoch 7: val_acc improved from 0.97579 to 0.97693, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.1073 - acc: 0.9699 - val_loss: 0.0852 - val_acc: 0.9769 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 8/1000\n",
            "\n",
            "Epoch 8: val_acc improved from 0.97693 to 0.97762, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.0971 - acc: 0.9727 - val_loss: 0.0794 - val_acc: 0.9776 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 9/1000\n",
            "\n",
            "Epoch 9: val_acc did not improve from 0.97762\n",
            "2463/2463 - 14s - loss: 0.0925 - acc: 0.9741 - val_loss: 0.0840 - val_acc: 0.9764 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 10/1000\n",
            "\n",
            "Epoch 10: val_acc improved from 0.97762 to 0.97921, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.0875 - acc: 0.9750 - val_loss: 0.0730 - val_acc: 0.9792 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 11/1000\n",
            "\n",
            "Epoch 11: val_acc improved from 0.97921 to 0.98173, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.0840 - acc: 0.9763 - val_loss: 0.0631 - val_acc: 0.9817 - lr: 0.0010 - 14s/epoch - 6ms/step\n",
            "Epoch 12/1000\n",
            "\n",
            "Epoch 12: val_acc did not improve from 0.98173\n",
            "2463/2463 - 15s - loss: 0.0797 - acc: 0.9769 - val_loss: 0.0658 - val_acc: 0.9809 - lr: 0.0010 - 15s/epoch - 6ms/step\n",
            "Epoch 13/1000\n",
            "\n",
            "Epoch 13: val_acc did not improve from 0.98173\n",
            "2463/2463 - 17s - loss: 0.0778 - acc: 0.9779 - val_loss: 0.0642 - val_acc: 0.9808 - lr: 0.0010 - 17s/epoch - 7ms/step\n",
            "Epoch 14/1000\n",
            "\n",
            "Epoch 14: val_acc did not improve from 0.98173\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "2463/2463 - 16s - loss: 0.0752 - acc: 0.9786 - val_loss: 0.0682 - val_acc: 0.9796 - lr: 0.0010 - 16s/epoch - 7ms/step\n",
            "Epoch 15/1000\n",
            "\n",
            "Epoch 15: val_acc improved from 0.98173 to 0.98492, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 17s - loss: 0.0573 - acc: 0.9832 - val_loss: 0.0498 - val_acc: 0.9849 - lr: 1.0000e-04 - 17s/epoch - 7ms/step\n",
            "Epoch 16/1000\n",
            "\n",
            "Epoch 16: val_acc improved from 0.98492 to 0.98572, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 17s - loss: 0.0508 - acc: 0.9847 - val_loss: 0.0482 - val_acc: 0.9857 - lr: 1.0000e-04 - 17s/epoch - 7ms/step\n",
            "Epoch 17/1000\n",
            "\n",
            "Epoch 17: val_acc improved from 0.98572 to 0.98641, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 17s - loss: 0.0482 - acc: 0.9857 - val_loss: 0.0459 - val_acc: 0.9864 - lr: 1.0000e-04 - 17s/epoch - 7ms/step\n",
            "Epoch 18/1000\n",
            "\n",
            "Epoch 18: val_acc did not improve from 0.98641\n",
            "2463/2463 - 16s - loss: 0.0455 - acc: 0.9866 - val_loss: 0.0461 - val_acc: 0.9862 - lr: 1.0000e-04 - 16s/epoch - 7ms/step\n",
            "Epoch 19/1000\n",
            "\n",
            "Epoch 19: val_acc did not improve from 0.98641\n",
            "2463/2463 - 16s - loss: 0.0447 - acc: 0.9865 - val_loss: 0.0443 - val_acc: 0.9863 - lr: 1.0000e-04 - 16s/epoch - 7ms/step\n",
            "Epoch 20/1000\n",
            "\n",
            "Epoch 20: val_acc improved from 0.98641 to 0.98687, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 15s - loss: 0.0427 - acc: 0.9872 - val_loss: 0.0445 - val_acc: 0.9869 - lr: 1.0000e-04 - 15s/epoch - 6ms/step\n",
            "Epoch 21/1000\n",
            "\n",
            "Epoch 21: val_acc improved from 0.98687 to 0.98698, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 16s - loss: 0.0422 - acc: 0.9871 - val_loss: 0.0431 - val_acc: 0.9870 - lr: 1.0000e-04 - 16s/epoch - 6ms/step\n",
            "Epoch 22/1000\n",
            "\n",
            "Epoch 22: val_acc improved from 0.98698 to 0.98732, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.0420 - acc: 0.9875 - val_loss: 0.0424 - val_acc: 0.9873 - lr: 1.0000e-04 - 14s/epoch - 6ms/step\n",
            "Epoch 23/1000\n",
            "\n",
            "Epoch 23: val_acc improved from 0.98732 to 0.98881, saving model to modified_cnn_mitbih.h5\n",
            "2463/2463 - 14s - loss: 0.0404 - acc: 0.9880 - val_loss: 0.0417 - val_acc: 0.9888 - lr: 1.0000e-04 - 14s/epoch - 6ms/step\n",
            "Epoch 24/1000\n",
            "\n",
            "Epoch 24: val_acc did not improve from 0.98881\n",
            "2463/2463 - 14s - loss: 0.0398 - acc: 0.9879 - val_loss: 0.0420 - val_acc: 0.9880 - lr: 1.0000e-04 - 14s/epoch - 6ms/step\n",
            "Epoch 25/1000\n",
            "\n",
            "Epoch 25: val_acc did not improve from 0.98881\n",
            "2463/2463 - 14s - loss: 0.0390 - acc: 0.9882 - val_loss: 0.0424 - val_acc: 0.9878 - lr: 1.0000e-04 - 14s/epoch - 6ms/step\n",
            "Epoch 26/1000\n",
            "\n",
            "Epoch 26: val_acc did not improve from 0.98881\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "2463/2463 - 14s - loss: 0.0379 - acc: 0.9881 - val_loss: 0.0415 - val_acc: 0.9885 - lr: 1.0000e-04 - 14s/epoch - 6ms/step\n",
            "Epoch 27/1000\n",
            "\n",
            "Epoch 27: val_acc did not improve from 0.98881\n",
            "2463/2463 - 14s - loss: 0.0366 - acc: 0.9888 - val_loss: 0.0411 - val_acc: 0.9878 - lr: 1.0000e-05 - 14s/epoch - 6ms/step\n",
            "Epoch 28/1000\n",
            "\n",
            "Epoch 28: val_acc did not improve from 0.98881\n",
            "2463/2463 - 14s - loss: 0.0360 - acc: 0.9893 - val_loss: 0.0410 - val_acc: 0.9881 - lr: 1.0000e-05 - 14s/epoch - 6ms/step\n",
            "Epoch 28: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "file_path = \"modified_cnn_mitbih.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "history = model.fit([X_ecg, X_physical], Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTXYfl5PAjp9",
        "outputId": "81472186-fda0-4d91-821f-f2d83fec6024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test f1 score : 0.9112856896270202 \n",
            "Test accuracy score : 0.9836926731226019 \n"
          ]
        }
      ],
      "source": [
        "pred_test = model.predict([X_ecg_test, X_physical_test])\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
        "\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YDIx-y4AlYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715c976c-8fca-4e6c-e221-0434a9669bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision : 0.9409927172866126, [0.98805741 0.90677966 0.95655221 0.86231884 0.99125547]\n",
            "Recall : 0.8858892089111169, [0.99547411 0.76978417 0.94267956 0.7345679  0.9869403 ]\n",
            "F1 Score : 0.9112856896270202, [0.9917519  0.83268482 0.94956522 0.79333333 0.98909318]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "precision, recall, fscore, support = score(Y_test, pred_test)\n",
        "print(\"Precision : %s, %s\" % (np.mean(precision), precision))\n",
        "print(\"Recall : %s, %s\" % (np.mean(recall), recall))\n",
        "print(\"F1 Score : %s, %s\" % (np.mean(fscore), fscore))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "df.to_csv('/content/drive/MyDrive/[Project] 윤정현 - ECG/Result/model1.csv')"
      ],
      "metadata": {
        "id": "Ptvz191Do-N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zmw3sUzgpsc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}